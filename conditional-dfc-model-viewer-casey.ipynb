{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d547fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f99e1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available() else\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available() else\n",
    "    torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MorphII_Dataset\n",
    "\n",
    "prepipeline = transforms.Compose([\n",
    "    transforms.ToPILImage(),             # Convert NumPy array to PIL Image\n",
    "    transforms.Resize((64, 64)),           # Resize to model's input dimensions\n",
    "    transforms.ToTensor(),                 # Convert image to tensor with values in [0,1]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1,1]\n",
    "])\n",
    "\n",
    "val_dataset = MorphII_Dataset(csv_file=\"Dataset/Index/Validation.csv\", transform=prepipeline)\n",
    "test_dataset = MorphII_Dataset(csv_file=\"Dataset/Index/Test.csv\", transform=prepipeline)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find image1.jpg. Please ensure the file exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Check if file exists\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(image_path):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please ensure the file exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Load and manually preprocess the image using PIL and numpy\u001b[39;00m\n\u001b[1;32m     42\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find image1.jpg. Please ensure the file exists."
     ]
    }
   ],
   "source": [
    "def generate_age_variation(model, image, cond, age_values):\n",
    "    \"\"\"\n",
    "    Given an image and its condition, encode it and then decode it\n",
    "    with varying age conditions.\n",
    "\n",
    "    Args:\n",
    "        model: Trained ConditionalVAE.\n",
    "        image: A single image tensor (C x H x W).\n",
    "        cond: Its corresponding condition tensor (age), shape [1].\n",
    "        age_values: Iterable of new normalized age values.\n",
    "\n",
    "    Returns:\n",
    "        List of generated images (tensors).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        cond = cond.unsqueeze(0).to(device)\n",
    "\n",
    "        mu, logvar = model.encoder(image, cond)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        for age in age_values:\n",
    "            new_cond = torch.tensor([[age]], dtype=torch.float32).to(device)\n",
    "            out = model.decoder(z, new_cond)\n",
    "            outputs.append(out)\n",
    "    return outputs\n",
    "\n",
    "# Load a specific image called \"image1\" without using torchvision\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1 is in the same directory or specify the path\n",
    "image_path = \"image1.jpg\"  # Adjust path as needed\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Could not find {image_path}. Please ensure the file exists.\")\n",
    "\n",
    "# Load and manually preprocess the image using PIL and numpy\n",
    "img = Image.open(image_path).convert('RGB')\n",
    "img = img.resize((64, 64), Image.Resampling.LANCZOS)\n",
    "img_np = np.array(img) / 255.0  # Normalize to [0,1]\n",
    "\n",
    "# Convert to PyTorch tensor and normalize to [-1,1]\n",
    "img_tensor = torch.from_numpy(img_np.transpose(2, 0, 1)).float()  # HWC to CHW format\n",
    "img_tensor = img_tensor * 2.0 - 1.0  # Convert [0,1] to [-1,1]\n",
    "\n",
    "# For the condition (age), we'll need to provide a value\n",
    "sample_cond = torch.tensor([0.5], dtype=torch.float32)  # Default to middle age (0.5)\n",
    "\n",
    "# Generate age variations\n",
    "age_range = np.linspace(0.0, 1.0, 10)\n",
    "generated_images = generate_age_variation(model, img_tensor, sample_cond, age_range)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(15, 3))\n",
    "# First show the original image\n",
    "img_display = (img_tensor.cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
    "plt.subplot(1, len(generated_images)+1, 1)\n",
    "plt.imshow(img_display)\n",
    "plt.title(f\"Original (Age: {sample_cond.item():.2f})\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Then show the age variations\n",
    "for i, gen in enumerate(generated_images):\n",
    "    gen_np = (gen.squeeze().cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
    "    plt.subplot(1, len(generated_images)+1, i+2)\n",
    "    plt.imshow(gen_np)\n",
    "    plt.title(f\"Age: {age_range[i]:.2f}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_age_variation(model, image, cond, age_values):\n",
    "    \"\"\"\n",
    "    Given an image and its condition, encode it and then decode it\n",
    "    with varying age conditions.\n",
    "\n",
    "    Args:\n",
    "        model: Trained ConditionalVAE.\n",
    "        image: A single image tensor (C x H x W).\n",
    "        cond: Its corresponding condition tensor (age), shape [1].\n",
    "        age_values: Iterable of new normalized age values.\n",
    "\n",
    "    Returns:\n",
    "        List of generated images (tensors).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        cond = cond.unsqueeze(0).to(device)\n",
    "\n",
    "        mu, logvar = model.encoder(image, cond)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        for age in age_values:\n",
    "            new_cond = torch.tensor([[age]], dtype=torch.float32).to(device)\n",
    "            out = model.decoder(z, new_cond)\n",
    "            outputs.append(out)\n",
    "    return outputs\n",
    "\n",
    "# Load a specific image called \"image1\" without using torchvision\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1 is in the same directory or specify the path\n",
    "image_path = \"image1.jpg\"  # Adjust path as needed\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Could not find {image_path}. Please ensure the file exists.\")\n",
    "\n",
    "# Load and manually preprocess the image using PIL and numpy\n",
    "img = Image.open(image_path).convert('RGB')\n",
    "img = img.resize((64, 64), Image.Resampling.LANCZOS)\n",
    "img_np = np.array(img) / 255.0  # Normalize to [0,1]\n",
    "\n",
    "# Convert to PyTorch tensor and normalize to [-1,1]\n",
    "img_tensor = torch.from_numpy(img_np.transpose(2, 0, 1)).float()  # HWC to CHW format\n",
    "img_tensor = img_tensor * 2.0 - 1.0  # Convert [0,1] to [-1,1]\n",
    "\n",
    "# For the condition (age), we'll need to provide a value\n",
    "sample_cond = torch.tensor([0.5], dtype=torch.float32)  # Default to middle age (0.5)\n",
    "\n",
    "# Generate age variations\n",
    "age_range = np.linspace(0.0, 1.0, 10)\n",
    "generated_images = generate_age_variation(model, img_tensor, sample_cond, age_range)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(15, 3))\n",
    "# First show the original image\n",
    "img_display = (img_tensor.cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
    "plt.subplot(1, len(generated_images)+1, 1)\n",
    "plt.imshow(img_display)\n",
    "plt.title(f\"Original (Age: {sample_cond.item():.2f})\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Then show the age variations\n",
    "for i, gen in enumerate(generated_images):\n",
    "    gen_np = (gen.squeeze().cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
    "    plt.subplot(1, len(generated_images)+1, i+2)\n",
    "    plt.imshow(gen_np)\n",
    "    plt.title(f\"Age: {age_range[i]:.2f}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
