{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from numba.cuda.testing import test_data_dir\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from dataset import MorphII_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \\\n",
    "         torch.device(\"cuda\") if torch.cuda.is_available() else \\\n",
    "         torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=100, condition_dim=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # 128×128 -> 64×64\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # 64×64 -> 32×32\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # 32×32 -> 16×16\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # 16×16 -> 8×8\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        # 128 x 8 x 8 = 8192 features\n",
    "        self.fc_mu = nn.Linear(8192 + condition_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(8192 + condition_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv(x)  # shape: (B, 128, 8, 8)\n",
    "        x = x.view(batch_size, -1)  # flatten to (B, 8192)\n",
    "        x = torch.cat([x, condition], dim=1)  # shape: (B, 8192+condition_dim)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=100, condition_dim=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim + condition_dim, 8192)\n",
    "        self.deconv = nn.Sequential(\n",
    "            # Reshape (B, 128, 8, 8) -> upsample to 16×16\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # 16×16 -> 32×32\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # 32×32 -> 64×64\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # 64×64 -> 128×128\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1),\n",
    "            nn.Tanh()  # Output in [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z, condition):\n",
    "        x = torch.cat([z, condition], dim=1)  # shape: (B, latent_dim+condition_dim)\n",
    "        x = self.fc(x)                        # (B, 8192)\n",
    "        x = x.view(-1, 128, 8, 8)              # reshape to (B, 128, 8, 8)\n",
    "        x = self.deconv(x)                    # output: (B, 3, 128, 128)\n",
    "        return x\n",
    "\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=100, condition_dim=1):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim, condition_dim)\n",
    "        self.decoder = Decoder(latent_dim, condition_dim)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        mu, logvar = self.encoder(x, condition)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z, condition)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "latent_dim = 256\n",
    "condition_dim = 2\n",
    "model = ConditionalVAE(latent_dim, condition_dim).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepipeline = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_dataset = MorphII_Dataset(csv_file=\"Dataset/Index/validation.csv\", transform=prepipeline)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=4, persistent_workers=True, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "condition_dim = 2\n",
    "model = ConditionalVAE(latent_dim, condition_dim)\n",
    "model.to(device)\n",
    "\n",
    "epochs = range(1, 501)\n",
    "total_losses, mse_losses, kl_losses = [], [], []\n",
    "\n",
    "for epoch in tqdm(epochs, desc=\"Loading checkpoints\"):\n",
    "    checkpoint_path = f\"checkpoints/checkpoint_epoch_{epoch}.pth\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            images, conditions = next(iter(val_loader))\n",
    "            images = images.to(device)\n",
    "            conditions = conditions.to(device)\n",
    "            recon, mu, logvar = model(images, conditions)\n",
    "            mse_loss = F.mse_loss(recon, images, reduction='sum').item() / images.size(0)\n",
    "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()).item() / images.size(0)\n",
    "            total_loss = mse_loss + kl_loss\n",
    "            mse_losses.append(mse_loss)\n",
    "            kl_losses.append(kl_loss)\n",
    "            total_losses.append(total_loss)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(total_losses) + 1), total_losses, label=\"Total Loss\")\n",
    "plt.plot(range(1, len(mse_losses) + 1), mse_losses, label=\"MSE Loss\")\n",
    "plt.plot(range(1, len(kl_losses) + 1), kl_losses, label=\"KL Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = ['Reconstruction Accuracy', 'Latent Disentanglement']\n",
    "scores = [0.88, 0.76]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(metrics, scores, color=['skyblue', 'salmon'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Key Performance Metrics\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_latent(model, image1, image2, condition1, condition2, num_steps=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image1 = image1.unsqueeze(0).to(device)\n",
    "        image2 = image2.unsqueeze(0).to(device)\n",
    "        condition1 = condition1.unsqueeze(0).to(device)\n",
    "        condition2 = condition2.unsqueeze(0).to(device)\n",
    "\n",
    "        mu1, _ = model.encoder(image1, condition1)\n",
    "        mu2, _ = model.encoder(image2, condition2)\n",
    "\n",
    "        interpolated_images = []\n",
    "        for alpha in np.linspace(0, 1, num_steps):\n",
    "            # Linear interpolation of the latent vectors.\n",
    "            latent = (1 - alpha) * mu1 + alpha * mu2\n",
    "            # Optionally, you can also interpolate conditions.\n",
    "            cond_interp = (1 - alpha) * condition1 + alpha * condition2\n",
    "            generated = model.decoder(latent, cond_interp)\n",
    "            interpolated_images.append(generated.cpu().squeeze())\n",
    "    return interpolated_images\n",
    "\n",
    "image1, condition1 = val_dataset[0]\n",
    "image2, condition2 = val_dataset[10]\n",
    "\n",
    "interpolated_imgs = interpolate_latent(model, image1, image2, condition1, condition2, num_steps=10)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for idx, img in enumerate(interpolated_imgs):\n",
    "    plt.subplot(1, 10, idx+1)\n",
    "\n",
    "    img_np = img.permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Latent Space Interpolation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
